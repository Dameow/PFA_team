from wordcloud import WordCloud
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
from lxml import etree
from nltk.tokenize import word_tokenize


# 去掉停用词：stop_words———停用词、虚词，如“the/a/of/and/on/” 
# 去除stop_words的操作，运行的时候，需要下载punkt，nltk.download('punkt') 
def remove_stop_words(f):
	stop_words = ['Movie']
	for stop_word in stop_words:
		f = f.replace(stop_word, '')
	return f

# 生成词云
def create_word_cloud(f):
	print('根据词频，开始生成词云!')
	f = remove_stop_words(f)
	cut_text = word_tokenize(f) 
	#print(cut_text)
	cut_text = " ".join(cut_text)

	#WordCloud就是词云工具
	wc = WordCloud(
		max_words=100,
		width=2000,
		height=1200,
    )
	wordcloud = wc.generate(cut_text)
	# 写词云图片
	wordcloud.to_file("wordcloud.jpg")
	# 显示词云文件
	plt.imshow(wordcloud)
	plt.axis("off")
	plt.show()

# 数据加载
data = pd.read_csv('./Market_Basket_Optimisation.csv',header=None)
transactions = []
for i in range(0,data.shape[0]):
	temp = []
	for j in range(0,20):
		item = str(data.values[i,j])
		if item!='nan':
			temp.append(item)
	transactions.append(temp)

all_word = ' '.join('%s' %item for item in transactions)
# 生成词云
create_word_cloud(all_word) 


